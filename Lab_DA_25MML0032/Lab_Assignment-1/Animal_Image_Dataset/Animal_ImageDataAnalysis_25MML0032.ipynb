{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee24c3cb-6da2-4548-943f-318bc6864cfb",
   "metadata": {},
   "source": [
    "Dataset type is Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df540a5-8c11-4dbe-804a-35e704973956",
   "metadata": {},
   "source": [
    "D. Sai Mohith 25MML0032"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e76f5d1-e052-4443-b65a-a63bd26246a2",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39da1ec3-337a-49e3-9999-91ed925b8838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "683a82e2-cd04-4022-afc4-018cdb329aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "Sample 10 types ['antelope', 'badger', 'bat', 'bear', 'bee', 'beetle', 'bison', 'boar', 'butterfly', 'cat']\n"
     ]
    }
   ],
   "source": [
    "datapath=\"C:/Users/dsnat/Downloads/animals/animals\"\n",
    "types=os.listdir(datapath)\n",
    "print(len(types))\n",
    "print(\"Sample 10 types\",types[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3438ac-40c8-4476-a009-dc68b1cc50ca",
   "metadata": {},
   "source": [
    "Finding Total Images and any corrupted images present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67185e51-bf28-4a4d-89dc-049bf4a8be5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Valid count 5400\n",
      "Length of corrupted Images 0\n"
     ]
    }
   ],
   "source": [
    "corrupt=[]\n",
    "count=0\n",
    "for Type in types:\n",
    "    type_path=os.path.join(datapath,Type)\n",
    "    for img in os.listdir(type_path):\n",
    "        img_path=os.path.join(type_path,img)\n",
    "        try:\n",
    "            Image.open(img_path).verify()\n",
    "            count=count+1\n",
    "        except:\n",
    "            corrupt.append(img_path)\n",
    "print(\"Total Valid count\",count)\n",
    "print(\"Length of corrupted Images\",len(corrupt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451bbbdd-e175-4929-8141-4a0f4f4eb862",
   "metadata": {},
   "source": [
    "Inspecting Image Modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9eac0ca9-1ec8-4d95-b82b-30a3a492fab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels and Types: Counter({'RGB': 5400})\n"
     ]
    }
   ],
   "source": [
    "mode=[]\n",
    "for Type in types:\n",
    "    type_path=os.path.join(datapath,Type)\n",
    "    for img in os.listdir(type_path):\n",
    "        img_path=os.path.join(type_path,img)\n",
    "        try:\n",
    "            img2=Image.open(img_path)\n",
    "            mode.append(img2.mode)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "print(\"Channels and Types:\",Counter(mode))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1befc3a-0d7e-43de-bb2c-b2cfeaf6675f",
   "metadata": {},
   "source": [
    "Image conversion into RBG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c213a0b8-3553-4d80-ab00-69ec67073171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_channels(img):\n",
    "    if img.mode==\"L\":       \n",
    "        img=img.convert(\"RGB\")\n",
    "    if img.mode==\"RGBA\":    \n",
    "        img=img.convert(\"RGB\")\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07499ce8-f7e6-490a-a5f3-51099e0ed8b9",
   "metadata": {},
   "source": [
    "Image Size Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d59dfd0e-ad0a-4f7e-8918-a0b22e31376a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((275, 183), 477), ((300, 168), 344), ((259, 194), 224), ((225, 225), 172), ((299, 168), 103), ((1200, 900), 62), ((1200, 675), 57), ((310, 163), 56), ((1200, 800), 55), ((1200, 1200), 53)]\n"
     ]
    }
   ],
   "source": [
    "size=[]\n",
    "for Type in types:\n",
    "    for f in os.listdir(os.path.join(datapath,Type)):\n",
    "        fpath=os.path.join(datapath,Type,f)\n",
    "        img=Image.open(fpath)\n",
    "        size.append(img.size)\n",
    "\n",
    "print(Counter(size).most_common(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0305e4db-7799-44ca-9df5-302d7a9bc019",
   "metadata": {},
   "source": [
    "Resizging of Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fca9ffeb-872a-4c96-b74d-7e09890b272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SIZE = (128, 128)\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for label, cls in enumerate(types):\n",
    "    cls_path = os.path.join(datapath, cls)\n",
    "    for f in os.listdir(cls_path):\n",
    "        fpath = os.path.join(cls_path, f)\n",
    "        try:\n",
    "            img = Image.open(fpath)\n",
    "            img = fix_channels(img)\n",
    "            img = img.resize(TARGET_SIZE)\n",
    "            X.append(np.array(img))\n",
    "            y.append(label)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8e6bb3d-3cbc-4972-9e44-77c244bad57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400, 128, 128, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe3d5447-933c-448e-9e40-db83d066fcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23922da-b7f4-4158-bd71-367b7bcedb7c",
   "metadata": {},
   "source": [
    "Image Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0ad410b-8668-4961-87c0-bafaae0d07a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.astype(\"float32\")/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2cf47ab3-6055-43ee-bc8f-595ff78216bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59f5f4d6-4c2e-4cc9-8c52-d031539dba47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5400, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "X_gray=np.array([cv2.cvtColor(x, cv2.COLOR_RGB2GRAY) for x in X])\n",
    "print(X_gray.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01998af0-1609-45e6-b611-a1ca1926810c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5400, 16384)\n"
     ]
    }
   ],
   "source": [
    "X_flat=X_gray.reshape(len(X_gray),-1)\n",
    "print(X_flat.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fb1760-d93a-4773-8b4f-ca21e62dad68",
   "metadata": {},
   "source": [
    "Spliting of data by converting them to numpy arrays first and using train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7ca0866-f391-40a1-be24-b49b4b74fd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_flat,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16c906d7-8e35-427e-b843-574007af7f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4320, 16384)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9936f4cb-84fe-400e-a666-abcb3904c25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4320,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml_lab]",
   "language": "python",
   "name": "conda-env-ml_lab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
