{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IcyLPGgChGr4"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MobileNetV2(weights='imagenet')"
      ],
      "metadata": {
        "id": "OizZVz63hktP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47cf265c-6c4d-40c1-e691-bb4b1bfab0ff"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
            "\u001b[1m14536120/14536120\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_frames(video_path, max_frames=20):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Cannot open video\")\n",
        "        return np.array([])\n",
        "\n",
        "    frames = []\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Handle videos where frame count is 0\n",
        "    if total_frames > 0:\n",
        "        step = max(1, total_frames // max_frames)\n",
        "    else:\n",
        "        step = 1\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if count % step == 0:\n",
        "            frame = cv2.resize(frame, (224, 224))\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # ğŸ”´ Important fix\n",
        "            frames.append(frame)\n",
        "\n",
        "        count += 1\n",
        "\n",
        "        if len(frames) >= max_frames:\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    print(\"Extracted frames:\", len(frames))\n",
        "    return np.array(frames)\n"
      ],
      "metadata": {
        "id": "eZJ8Sxh-idJV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_video(video_path):\n",
        "    frames = extract_frames(video_path)\n",
        "\n",
        "    if len(frames) == 0:\n",
        "        print(\"No frames extracted!\")\n",
        "        return\n",
        "\n",
        "    frames = preprocess_input(frames)\n",
        "    predictions = model.predict(frames)\n",
        "\n",
        "    # Average predictions across frames\n",
        "    avg_pred = np.mean(predictions, axis=0)\n",
        "    #top_pred = decode_predictions(np.expand_dims(avg_pred, axis=0), top=1)\n",
        "\n",
        "    top_pred = decode_predictions(np.expand_dims(avg_pred, axis=0), top=5)\n",
        "\n",
        "    for pred in top_pred[0]:\n",
        "      print(pred[1], \":\", round(pred[2]*100, 2), \"%\")\n",
        "\n",
        "\n",
        "    print(\"Final Prediction:\", top_pred[0][0][1])"
      ],
      "metadata": {
        "id": "jjjyThggijiO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with your video path\n",
        "video_path = \"/content/01_002.avi\"\n",
        "classify_video(video_path)"
      ],
      "metadata": {
        "id": "n1rQvL0milqb",
        "outputId": "7b962b87-0932-4f55-b74e-6c30e874919b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted frames: 20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "\u001b[1m35363/35363\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "unicycle : 25.92 %\n",
            "racket : 5.14 %\n",
            "tripod : 4.27 %\n",
            "sundial : 3.15 %\n",
            "hook : 2.48 %\n",
            "Final Prediction: unicycle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sMt5yrIQiq00"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}